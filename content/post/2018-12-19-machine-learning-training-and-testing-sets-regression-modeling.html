---
title: 'Machine Learning - Training and Testing Sets: Regression Modeling'
author: Michael Fuchs
date: '2018-12-19'
slug: machine-learning-training-and-testing-sets-regression-modeling
categories:
  - R
tags:
  - R Markdown
---



<pre class="r"><code>library(tidyverse)</code></pre>
<div id="table-of-content" class="section level1">
<h1>Table of Content</h1>
<ul>
<li>1 Introduction</li>
<li>2 Creation of two dependent variables</li>
<li>3 Train and test the simple regression model</li>
<li>4 Train and test the polynomial regression model</li>
<li>5 Train and test the exponential regression model</li>
<li>6 Conclusion</li>
</ul>
</div>
<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>This post deals with the subject of machine learning. In particular, the training and testing of data for a regression analysis will be considered.</p>
</div>
<div id="creation-of-two-dependent-variables" class="section level1">
<h1>2 Creation of two dependent variables</h1>
<p>In the first step, two interdependent variables are generated.</p>
<pre class="r"><code>x &lt;- rnorm(100, 2, 1)
y &lt;- exp(x) + rnorm(7, 0, 1)</code></pre>
<pre><code>## Warning in exp(x) + rnorm(7, 0, 1): L채nge des l채ngeren Objektes
##       ist kein Vielfaches der L채nge des k체rzeren Objektes</code></pre>
<pre class="r"><code>linear &lt;- lm(y  ~ x)</code></pre>
<pre class="r"><code>plot(x, y)
abline(a = coef(linear[1], b = coef(linear[2], lty = 2)))</code></pre>
<p><img src="/post/2018-12-19-machine-learning-training-and-testing-sets-regression-modeling_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>summary(linear)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -8.757 -6.048 -2.431  1.917 48.820 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -14.646      2.256  -6.492  3.5e-09 ***
## x             13.485      1.004  13.429  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.862 on 98 degrees of freedom
## Multiple R-squared:  0.6479, Adjusted R-squared:  0.6443 
## F-statistic: 180.3 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="train-and-test-the-simple-regression-model" class="section level1">
<h1>3 Train and test the simple regression model</h1>
<p>Subsequently, the newly created data set is divided into a training part (80%) and a test part (20%).</p>
<pre class="r"><code>data &lt;- data.frame(x, y)
data.samples &lt;- sample(1:nrow(data), nrow(data) * 0.8, replace = FALSE)
training.data &lt;- data[data.samples, ]
test.data &lt;- data[-data.samples, ]</code></pre>
<p>Now the regression model can be traniniert with the training data.</p>
<pre class="r"><code>train.linear &lt;- lm(y ~ x, training.data)
train.output &lt;- predict(train.linear, test.data)</code></pre>
<p>The quality of the prediction can be determined using the root mean square error (RMSE).</p>
<p><span class="math display">\[RMSE = \sqrt{\frac{1}{n}\Sigma_{i=1}^{n}{\Big(\frac{d_i -f_i}{\sigma_i}\Big)^2}}\]</span></p>
<pre class="r"><code>RMSE.df &lt;- data.frame(predicted = train.output, actual = test.data$y, 
                      SE = ((train.output - test.data$y)^2/length(train.output)))

head(RMSE.df)</code></pre>
<pre><code>##    predicted     actual          SE
## 6  22.321484 16.6759492  1.59360324
## 10 43.877682 86.4671438 90.69311316
## 18  3.402436  2.3673990  0.05356511
## 21  5.583836  5.5309396  0.00013990
## 23 -7.723548  0.2264205  3.16009986
## 32  5.433504  2.9935479  0.29766928</code></pre>
<pre class="r"><code>sqrt(sum(RMSE.df$SE))</code></pre>
<pre><code>## [1] 10.6735</code></pre>
<p>We get a RMSE value of 8.15. To see how good this value is, it can be compared to other RMSE values.</p>
</div>
<div id="train-and-test-the-polynomial-regression-model" class="section level1">
<h1>4 Train and test the polynomial regression model</h1>
<pre class="r"><code>train.polyn &lt;- lm(y ~ poly(x, 4), training.data)
polyn.output &lt;- predict(train.polyn, test.data)

RMSE.polyn.df &lt;- data.frame(predicted = polyn.output, actual = test.data$y, 
                                  SE = ((polyn.output - test.data$y)^2/length(polyn.output)))

head(RMSE.polyn.df)</code></pre>
<pre><code>##    predicted     actual         SE
## 6  15.470405 16.6759492 0.07266679
## 10 87.466424 86.4671438 0.04992809
## 18  3.901215  2.3673990 0.11762952
## 21  4.623741  5.5309396 0.04115046
## 23  1.227808  0.2264205 0.05013880
## 32  4.571842  2.9935479 0.12455057</code></pre>
<pre class="r"><code>sqrt(sum(RMSE.polyn.df$SE))</code></pre>
<pre><code>## [1] 1.387238</code></pre>
<p>With a RMSE value of 0.79, we can see that the quality of the prediction has already improved significantly.</p>
</div>
<div id="train-and-test-the-exponential-regression-model" class="section level1">
<h1>5 Train and test the exponential regression model</h1>
<pre class="r"><code>train.exponential &lt;- lm(y ~ exp(x) + x, training.data)
exponential.output &lt;- predict(train.exponential, test.data)

RMSE.exponential.df &lt;- data.frame(predicted = exponential.output, actual = test.data$y, 
                                  SE = ((exponential.output - test.data$y)^2/length(exponential.output)))

head(RMSE.exponential.df)</code></pre>
<pre><code>##    predicted     actual         SE
## 6  15.763099 16.6759492 0.04166478
## 10 87.395915 86.4671438 0.04313083
## 18  3.702882  2.3673990 0.08917579
## 21  4.323283  5.5309396 0.07292177
## 23  1.921979  0.2264205 0.14374587
## 32  4.276605  2.9935479 0.08231182</code></pre>
<pre class="r"><code>sqrt(sum(RMSE.exponential.df$SE))</code></pre>
<pre><code>## [1] 1.329125</code></pre>
<p>An even better predictive value we get in this case with the exponential regression model. RMSE = 0.53</p>
</div>
<div id="conclusion" class="section level1">
<h1>6 Conclusion</h1>
<p>This should be a brief demonstration of how regression models can be trained and their predictive power improved.</p>
</div>
