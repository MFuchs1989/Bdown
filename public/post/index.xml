<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Michael Fuchs</title>
    <link>/post/</link>
    <description>Recent content in Posts on Michael Fuchs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Python Test</title>
      <link>/2019/08/12/python-test/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/12/python-test/</guid>
      <description>Hi das ist ein Python Test …
library(tidyverse)red &amp;lt;- read.csv(url(&amp;quot;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv&amp;quot;), sep = &amp;quot;;&amp;quot;)flight.head()hi
alt-Text-for-figure
</description>
    </item>
    
    <item>
      <title>Machine Learning - Predictions with ordinal logistic regression</title>
      <link>/2019/01/13/machine-learning-predictions-with-ordinal-logistic-regression/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/13/machine-learning-predictions-with-ordinal-logistic-regression/</guid>
      <description>library(tidyverse)library(ROCR)library(MASS)library(caret)library(nnet)Table of Content1 Introduction2 Load and prepare the dataset3 Prepare a training and test set4 Some descriptive key figures5 Conclusion1 IntroductionIn my last publication, “Machine Learning - Predictions with Generalized Linear Models”, the topic was discussed, how classifications can be made using generalized linear regressions. In the following, for example, a classification of an ordinal-scaled dependent variable shall be made.</description>
    </item>
    
    <item>
      <title>Machine Learning - Predictions with Generalized Linear Models</title>
      <link>/2019/01/12/machine-learning-predictions-with-generalized-linear-models/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/12/machine-learning-predictions-with-generalized-linear-models/</guid>
      <description>library(tidyverse)library(caret)library(glmnet)library(ROCR)Table of Content1 Introduction2 Load and prepare the dataset3 Train the model4 Manual calculation of some key figures4.1 p value of Thal74.2 Model deviance4.3 Null deviance4.4 Pseudo R24.5 Model deviance residuals5 Test set performance6 Regularization with lasso6.1 Classification accuracy for the train set6.2 Classification accuracy for the test set7 Classification metrics8 Conclusion1 IntroductionIn my last post (“Machine Learning - Predictions with linear regressions”) I treated the topic of predicting numerical values using regression models.</description>
    </item>
    
    <item>
      <title>Machine Learning - Predictions with linear regressions</title>
      <link>/2019/01/11/machine-learning-predictions-with-linear-regressions/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/11/machine-learning-predictions-with-linear-regressions/</guid>
      <description>library(tidyverse)library(caret)library(car)library(glmnet)machine &amp;lt;- read_csv(&amp;quot;machine.csv&amp;quot;)cars &amp;lt;- read_csv(&amp;quot;cars.csv&amp;quot;)Table of Content1 Introduction2 Presentation of the data records used3 Dividing the data into a training part and a test part4 Removing problematic features4.1 Machine dataset4.2 Cars dataset5 Assessing linear regression models6 How to check some summary outputs individually6.1 Residual analysis6.2 Significance tests for linear regression6.3 Residual standard error (RSE)6.</description>
    </item>
    
    <item>
      <title>Machine Learning - Cluster Analysis</title>
      <link>/2019/01/04/machine-learning-cluster-analysis/</link>
      <pubDate>Fri, 04 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/04/machine-learning-cluster-analysis/</guid>
      <description>library(tidyverse)library(gridExtra)library(cluster) library(factoextra)library(mclust)library(dbscan)iris &amp;lt;- read_csv(&amp;quot;Iris_Data.csv&amp;quot;)Table of Content1 Introduction2 Preparation3 k-Means3.1 Choosing k4 Hierachical clustering5 Model based clustering6 Density based clustering7 Conclusion1 IntroductionThe cluster analysis groups examination objects into natural groups (so-called “clusters”). The objects to be examined may be individuals, objects as well as countries or organizations. By applying cluster analytic methods, these objects can be clustered by their properties.</description>
    </item>
    
    <item>
      <title>Machine Learning - k-Means algorithm. An intuition.</title>
      <link>/2019/01/02/machine-learning-k-means-algorithm-an-intuition/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/02/machine-learning-k-means-algorithm-an-intuition/</guid>
      <description>library(tidyverse)library(mclust)cities15000_csv &amp;lt;- read_csv(&amp;quot;cities15000.csv&amp;quot;)Table of Content1 Introduction2 k-Means3 Conclusion1 IntroductionThe k-means algorithm is a calculation method that can be used for grouping objects, the so-called cluster analysis. Thanks to the efficient calculation of the cluster centers and the low memory requirements, the algorithm is very well suited for the analysis of large amounts of data, as is usual in the big data environment.</description>
    </item>
    
    <item>
      <title>Machine Learning - Linear Discriminant Analysis (LDA)</title>
      <link>/2018/12/29/machine-learning-linear-discriminant-analysis-lda/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/29/machine-learning-linear-discriminant-analysis-lda/</guid>
      <description>library(tidyverse)library(MASS)library(gridExtra)iris &amp;lt;- read_csv(&amp;quot;Iris_Data.csv&amp;quot;)Table of Content1 Introduction2 The way LDA works3 PCA vs. LDA4 Closing word1 IntroductionLinear discriminant analysis (LDA) is a type of linear combination, a mathematical process using various data items and applying functions to that set to separately analyze multiple classes of objects or items. LDA is most commonly used as dimensionality reduction technique in the pre-processing step for pattern-classification and machine learning applications.</description>
    </item>
    
    <item>
      <title>Machine Learning - Principal Component Analysis (PCA)</title>
      <link>/2018/12/28/machine-learning-principal-component-analysis-pca/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/28/machine-learning-principal-component-analysis-pca/</guid>
      <description>library(tidyverse)mtcars &amp;lt;- read_csv(&amp;quot;mtcars.csv&amp;quot;)Table of Content1 Introduction2 The way PCA works3 Closing word1 IntroductionPrincipal Component Analysis (PCA) is used when you want to structure or simplify a large data set. An attempt is made to reduce the total number of measured variables while still accounting for the largest possible portion of the variance of all variables. The PCA works purely exploratory and searches in the data for a linear pattern that best describes the data set.</description>
    </item>
    
    <item>
      <title>Machine Learning - Decision Trees</title>
      <link>/2018/12/27/machine-learning-decision-trees/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/27/machine-learning-decision-trees/</guid>
      <description>library(tidyverse)library(rpart)library(caret)library(randomForest)library(party)cu_summary &amp;lt;- read_csv(&amp;quot;cu.summary.csv&amp;quot;)Table of Content1 Introduction2 A simple tree model2.1 Tree entropy and information gain2.2 Visualize a simple tree model3 Prune tree4 Decision trees for regression5 Decision trees for classification6 Conditional inference trees7 Closing word1 IntroductionDecision trees are ordered, directed trees that serve to represent decision rules. The graphical representation as a tree diagram illustrates hierarchically successive decisions.</description>
    </item>
    
    <item>
      <title>Machine Learning - Regression Regularization</title>
      <link>/2018/12/25/machine-learning-regression-regularization/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/25/machine-learning-regression-regularization/</guid>
      <description>library(tidyverse)library(lasso2)mtcars &amp;lt;- read_csv(&amp;quot;mtcars.csv&amp;quot;)Table of Content1 Introduction2 The regularization of a regression3 Conclusion1 IntroductionRegularization is the tuning of the preferred complexity of the statistical model, so that the predictive ability of the model is improved. If you do not use regularization, the model can become too complex and over-fit, or too simple and under-fit the data.
For this post the dataset mtcars from the statistic platform “Kaggle” was used.</description>
    </item>
    
    <item>
      <title>Machine Learning - Cross-Validation</title>
      <link>/2018/12/19/machine-learning-cross-validation/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/19/machine-learning-cross-validation/</guid>
      <description>library(tidyverse)Table of Content1 Introduction2 Creation of two dependent variables3 The training and testing of a regression model with a simple random sample4 The training and testing of a regression model with cross validation5 Conclusion1 IntroductionCross validation is a technique for evaluating the performance of a model in machine learning. With new datasets, which were not used in the training phase, the quality of the prediction is checked.</description>
    </item>
    
    <item>
      <title>Machine Learning - Training and Testing Sets: Regression Modeling</title>
      <link>/2018/12/18/machine-learning-training-and-testing-sets-regression-modeling/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/18/machine-learning-training-and-testing-sets-regression-modeling/</guid>
      <description>library(tidyverse)Table of Content1 Introduction2 Creation of two dependent variables3 Train and test the simple regression model4 Train and test the polynomial regression model5 Train and test the exponential regression model6 Conclusion1 IntroductionThis post deals with the subject of machine learning. In particular, the training and testing of data for a regression analysis will be considered.
2 Creation of two dependent variablesIn the first step, two interdependent variables are generated.</description>
    </item>
    
    <item>
      <title>Web Scraping and Text Mining. An intuition.</title>
      <link>/2018/12/13/web-scraping-and-text-mining-an-intuition/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/13/web-scraping-and-text-mining-an-intuition/</guid>
      <description>library(tidyverse)library(rvest)library(RColorBrewer)library(wordcloud)library(tidytext)Table of Content1 Introduction2 What is Web Scraping?3 Annotation4 The web scraping process5 A few graphic analysis6 A brief insight of text mining7 Conclusion1 IntroductionThe amount of data and information available on the Internet is growing exponentially. The amount of data available on the Web opens up new possibilities for a data scientist, such as web scraping.</description>
    </item>
    
    <item>
      <title> Interactive Web Applications with Shiny. An intuition.</title>
      <link>/2018/10/19/interactive-web-applications-with-shiny-an-intuition/</link>
      <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/19/interactive-web-applications-with-shiny-an-intuition/</guid>
      <description>library(tidyverse)library(shiny)Table of Content1 Introduction2 Preparation“3 Scatter Plot”“4 Scatter Plot with slider input”“5 Scatter Plot plus Density Plot”“6 Scatter Plot plus Correlation”“7 Scatter Plot plus regression analysis”8 Conclusion1 IntroductionShiny ist ein R-Paket, mit dem man interaktive Web-Apps direkt aus R heraus erstellen kann. In R Studio gibt es dafür zwei Möglichkeiten.
File -&amp;gt; New File -&amp;gt; Shiny Wep App…</description>
    </item>
    
    <item>
      <title>Cleaning Data with tidyverse</title>
      <link>/2018/10/12/cleaning-data-with-tidyverse/</link>
      <pubDate>Fri, 12 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/12/cleaning-data-with-tidyverse/</guid>
      <description>library(tidyverse)Table of Content1 Introduction2 gather() and spread()3 separate() and unite()4 delete() and omit()5 Conclusion1 IntroductionDie meisten Datensätze mit denen man arbeiten möchte enthalten “unsaubere” Daten. Diese zu bereinigen, stellt demnach eine zentrale Tätigkeit in der Datenanalyse dar. In diesem Beitrag sollen folgende drei Methoden für eine saubere Aufbereitung des Datensatzes vorgesellt werden:
gather() and spread()separate() and unite()delete() and omit()Für diesen Post wurde der Datensatz IMDB-Movie-Data von der Statistik Plattform “Kaggle” verwendet.</description>
    </item>
    
    <item>
      <title>Confirmatory Factor Analysis</title>
      <link>/2018/10/11/confirmatory-factor-analysis/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/11/confirmatory-factor-analysis/</guid>
      <description>library(psych)library(lavaan)library(readxl)Arbeitszufriedenheit &amp;lt;- read_excel(&amp;quot;Arbeitszufriedenheit.xlsx&amp;quot;)Table of Content1 Introduction2 One-factorial model3 Comparative observation4 Conclusion1 IntroductionIn dem Beitrag zur “exploratorischen Faktorenanalyse” wurde bereits erwähnt, dass die konfirmatorische Faktorenanalyse als Strukturgleichungsmodell angewendet werden sollte, wenn die Faktorstruktur eines Datensatzes bereits bekannt ist. Nachfolgend soll dieses Verfahren vorgestellt werden.
Für die exemplarische Durchführung der konfirmatorischen Faktorenanalyse wurde der Datensatz Arbeitszufriedenheit verwendet. Eine Kopie des Datensatzes ist unter https://drive.</description>
    </item>
    
    <item>
      <title>Exploratory Factor Analysis</title>
      <link>/2018/10/07/exploratory-factor-analysis/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/07/exploratory-factor-analysis/</guid>
      <description>library(tidyverse)library(psych)library(readxl)library(GPArotation)BigFive &amp;lt;- read_excel(&amp;quot;BigFive.xlsx&amp;quot;)Table of Content1 Introduction2 Determination of the number of factors3 Execution of the factor analysis4 Conclusion1 IntroductionMithilfe der exploratorischen Faktorenanalyse kann aus den Beobachtungen vieler manifester Variablen (beispielsweise Items eines Fragebogens) auf wenige zugrunde liegende latente Variablen geschlossen werden. Diese latenten Variablen werden Faktoren genannt. Eine Faktorenanalyse führt demnach zu einer Reduktion der Variablen auf wenige, den manifesten Variablen zugrunde liegende, Faktoren.</description>
    </item>
    
    <item>
      <title> Nonparametric Methods</title>
      <link>/2018/10/04/nonparametric-methods/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/04/nonparametric-methods/</guid>
      <description>library(nortest)library(tidyverse)library(psych)insurance &amp;lt;- read_csv(&amp;quot;insurance.csv&amp;quot;)countries &amp;lt;- read_csv(&amp;quot;countries of the world.csv&amp;quot;)Table of Content1 Introduction2 Chi2-test3 Wilcoxon-test4 Kruskal-Wallis-test5 Conclusion1 IntroductionBei den zwei vorgestellten inferenzstatistischen Tests (“T-Test” und “ANOVA”) handelte es sich um so genannte parametrische Verfahren. Als Voraussetzung für parametrische Verfahren gilt, dass die unabhängige Variable mindestens intervallskaliert oder normalverteilt ist. Ist eine der beiden Voraussetzung nicht erfüllt, muss auf ein nonparametrisches Verfahren zurückgegriffen werden.</description>
    </item>
    
    <item>
      <title>Choosing the correct statistical test in R</title>
      <link>/2018/10/04/choosing-the-correct-statistical-test-in-r/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/04/choosing-the-correct-statistical-test-in-r/</guid>
      <description>In diesem Post soll zusammengefasst werden, unter welchen Umständen welcher (statistische) Test anzuwenden ist.
MittelwertsvergleicheFragestellung-Normalverteilung-VarianzhomogenitätTestVergleich von zwei Gruppen aus einer Stichprobejaja“T-Test” für unabhängige Stichprobens.o.janeinWelch Tests.o.neinnein“Wilcoxon Test”Vergleich von mehr als zwei Gruppen aus einer Stichprobejajaeinfaktorelle Varianzanalyse (“ANOVA”) ohne Messwiederholungs.</description>
    </item>
    
    <item>
      <title>Cronbachs Alpha</title>
      <link>/2018/10/03/cronbachs-alpha/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/03/cronbachs-alpha/</guid>
      <description>library(tidyverse)library(psych)World_Happiness_Report &amp;lt;- read_csv(&amp;quot;World_Happiness_Report.csv&amp;quot;)Table of Content1 Introduction2 Internal consistency3 Interpretation4 Conclusion1 IntroductionDas Ziel eines psychologischen Tests ist immer, Unterschiede zwischen Individuen hinsichtlich bestimmter Konstrukte aufzudecken. Um dies bestmöglich zu gewährleisten, muss man bei der Auswahl an Items ansetzen. Folgende Punkte sind für die Güte eines Items ausschlaggebend:
Beitrag zur Reliabilität. Das Item sollte die Reliabilität einer Skala verbessern.Schwierigkeit.</description>
    </item>
    
    <item>
      <title>Special Regression Analysis</title>
      <link>/2018/10/02/special-regression-analysis/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/02/special-regression-analysis/</guid>
      <description>library(tidyverse)library(psych)library(rockchalk)library(bda)affairs &amp;lt;- read_csv(&amp;quot;Affairs.csv&amp;quot;)Table of Content1 Introduction2 Categorical predictors3 Moderated regression4 Mediation5 Non-linear regression6 Analysis of covariance (ANCOVA)7 Logistic regression8 Conclusion1 IntroductionAufbauend auf den Post “Regression Analysis” soll im Nachfolgenden spezielle Regressionsmodelle vorgestellt werden.
Für diesen Beitrag wurde der Datensatz Affairs von der Statistik Plattform “Kaggle” verwendet. Eine Kopie des Datensatzes ist unter https://drive.</description>
    </item>
    
    <item>
      <title>Automation and Iteration</title>
      <link>/2018/09/29/automation-and-iteration/</link>
      <pubDate>Sat, 29 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/29/automation-and-iteration/</guid>
      <description>Table of Content1 Introduction2 purrr::map() function3 How to request with map() some statistical values4 How to use map() for multiple t-tests5 How to use map() for multiple linear regressions6 Conclusionlibrary(tidyverse)library(purrr)library(broom)library(knitr)library(psych)affairs &amp;lt;- read_csv(&amp;quot;Affairs.csv&amp;quot;)1 IntroductionSehr häufig werden R-Befehle per Copy &amp;amp; Paste vervielfacht und anschließend für unterschiedliche Zwecke leicht abgewandelt. Dies ist nicht nur umständlich, sondern auch leicht fehleranfällig.</description>
    </item>
    
    <item>
      <title>Identification of Outliers</title>
      <link>/2018/09/22/identification-of-outliers/</link>
      <pubDate>Sat, 22 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/22/identification-of-outliers/</guid>
      <description>library(tidyverse)library(outliers)Table of Content1 Introduction2 Identification of outliers3 Conclusion1 IntroductionIn der Statistik spricht man von Outlieren oder Ausreißern, wenn Messwerte nicht in eine erwartete Messreihe passen, da sie auffällig höher oder niedriger ausfallen. In diesem Post wird der Frage nachgegangen, wie Outlier identifiziert werden können.
2 Identification of outliersNeben der Möglichkeit, Ausreißer per Grafik zu identifizieren, kann in R auch der Grubbs-Test angewendet werden.</description>
    </item>
    
    <item>
      <title>Regression Analysis</title>
      <link>/2018/09/21/regression-analysis/</link>
      <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/21/regression-analysis/</guid>
      <description>Table of Content1 Introduction2 Preparation3 Bivariate linear regression3.1 Unstandardized regression coefficients3.2 Standardized regression coefficients3.3 Significance tests3.4 Confidence interval3.5 Predicted values4 Multiple linear regression4.1 Multiple correlation4.2 Hierarchical regression4.3 Gradual regression5 Model assumption6 Partial correlation and semi partial correlation6.1 Partial correlation6.2 Semi partial correlation7 Conclusion1 IntroductionMit einer Regressionsanalyse wird der Zusammenhang zwischen einer oder mehrerer unabhängigen Variablen und einer abhängigen Variablen ermittelt.</description>
    </item>
    
    <item>
      <title>MANOVA</title>
      <link>/2018/09/18/manova/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/18/manova/</guid>
      <description>Table of Content1 Introduction2 Preparation3 Essential requirements3.1 Normal distribution3.2 Sampling size3.3 Homogeneity of variance4 MANOVA5 Interaction diagram6 Post-hoc-method7 Effect size8 Conclusion1 IntroductionAufbauend auf den Post “ANOVA”, in dem es um die Funktionsweise der einfaktoriellen Varianzanalyse ging, soll nachfolgend das Prinzip der mehrfaktoriellen Varianzanalyse ohne Messwiederholung, kurz MANOVA (multivariate analysis of variance), näher erläutert werden. Im Gegensatz zur einfaktoriellen Varianzanalyse werden bei der MANOVA nicht nur eine, sondern mehrere unabhängige Variablen betrachtet.</description>
    </item>
    
    <item>
      <title>Effect Size and Power Analysis</title>
      <link>/2018/09/15/effect-size-and-power-analysis/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/15/effect-size-and-power-analysis/</guid>
      <description>Table of Content1 Introduction2 Effect Size3 Power Analysis4 Conclusion1 IntroductionNach der Vorstellung der zwei statistischen Testverfahren (“t-Test” und “ANOVA”), bei denen jeweils die Effektstärke und die Teststärke berechnet wurde, soll in diesem Post die Bedeutung und Interpretation dieser beiden Maße näher beschrieben werden.
2 Effect SizeAls Effektgröße wird in der Statistik ein Maß bezeichnet, welches die relative Größe eines Effektes angibt.</description>
    </item>
    
    <item>
      <title>ANOVA</title>
      <link>/2018/09/13/anova/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/13/anova/</guid>
      <description>Table of Content1 Introduction2 Preparation3 Essential requirements3.1 Normal distribution3.2 Sampling size3.3 Homogeneity of variance4 ANOVA with variance homogeneity5 ANOVA with variance inequality6 Post-hoc-method7 Effect size7.1 Effect size for ANOVA with variance homogeneity7.2 Effect size for ANOVA with variance inequality7.3 Calculation of Cohens f8 Power9 Outliers10 Conclusion1 IntroductionIm letzten Post “t-Test” ging es hauptsächlich um die Funktionsweise eines t-Tests für unabhängigen Stichproben.</description>
    </item>
    
    <item>
      <title>t-Test</title>
      <link>/2018/09/12/t-test/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/12/t-test/</guid>
      <description>Table of Content1 Introduction2 Preparation3 Essential requirements3.1 Normal distribution3.2 Sampling size3.3 Homogeneity of variance4 t-Test with variance homogeneity5 t-Test with variance inequality6 Directed hypothesis7 Adjust confidence interval8 Effect size9 Power10 Conclusion1 IntroductionEin t-Test kann verwendet werden, um Mittelwertsunterschiede zu überprüfen.
Wenn man den Stichprobenmittelwert von einer Variablen mit einem bekannten Populationsmittelwert vergleichen möchte, so wird ein t-Test für eine Stichprobe verwendet.</description>
    </item>
    
    <item>
      <title>Bivariate descriptive statistics</title>
      <link>/2018/09/04/bivariate-descriptive-statistics/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/04/bivariate-descriptive-statistics/</guid>
      <description>Table of Content1 Introduction2 Contingency table2.1 Absolute Frequency2.2 Relative Frequency2.3 Multidimensional contingency tables3.1 Pearsons correlation3.2 Covariance4 Correlations for non-metric variables4.1 metric - ordinal4.2 ordinal - ordinal5 Conclusion1 IntroductionAufbauend auf dem vorangegangenen Post “Univariate descriptive statistics” wird im folgenden Beitrag die gleichzeitige Betrachtung von zwei Variablen thematisiert. Für diesen Post werden die Datensätze insurance und Automobile_data von der Statsistik Plattform Kaggle https://www.</description>
    </item>
    
    <item>
      <title>Univariate descriptive statistics</title>
      <link>/2018/08/31/univariate-descriptive-statistics/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/31/univariate-descriptive-statistics/</guid>
      <description>Table of Content1 Introduction2 Frequency Tables2.1 Absolute Frequency2.2 Relative Frequency2.3 Cumulate Frequency2.4 Integration of frequencies within a single table3 Description of nominal data3.1 Mode3.2 Relative information content4 Description of ordinal data4.1 Percentile ranks4.2 Median4.3 Range4.4 Quantile5 Description of interval data5.1 Arithmetical mean5.2 Standard deviation5.3 Skewness and Kurtosis5.4 describe function5.5 summary function5.</description>
    </item>
    
    <item>
      <title>Measures of Dispersion</title>
      <link>/2018/08/26/measures-of-dispersion/</link>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/26/measures-of-dispersion/</guid>
      <description>Table of Content1 Introduction2 Dispersion2.1 Mean absolute deviation2.2 Variance2.3 Standard deviation2.4 Variation coefficient2.5 Range2.6 Interquartile range3 Conclusion1 IntroductionNehmen wir an, wir wollen für ein Jahr in ein uns unbekanntes Land reisen und wir müssten nun unseren Kleidungskoffer packen. Als einzige Information zu dem Land haben wir die Durchschnittstemperatur von 18 Grad Celsius. Reicht uns diese Angabe aus, um eine vernünftige Einschätzung treffen zu können?</description>
    </item>
    
    <item>
      <title>z-Transformation / Standardization</title>
      <link>/2018/08/25/z-transformation-standardization/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/25/z-transformation-standardization/</guid>
      <description>1 IntroductionDurch eine z-Transformation / Standardisierung von Merkmalen / Variablen werden diese in der Statistik in eine andere Form überführt. Dies ist beispielsweise notwendig, um unterschiedlich verteilte Zufallsvariablen miteinander vergleichen zu können. Dazu subtrahiert man von jedem Messwert den arithmetischen Mittelwert, teilt die resultierende Differenz durch die Standardabweichung und erhält dadurch die sogenannten z-scores (z-Werte).
\[ z = \frac{x-m}{sd} \]
z: z-transformierte Stichprobenwertex: Originalwert der Stichprobem: Mittelwert der Stichprobesd: Standardabweichung der StichprobeNach der z-Transformation ist</description>
    </item>
    
    <item>
      <title>Change Variables in R</title>
      <link>/2018/08/24/edit-variables-in-r/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/24/edit-variables-in-r/</guid>
      <description>Table of Content1 Introduction2 Choose variables2.1 $ sign2.2 Index Function2.3 Mulitble choose of variables2.3.1 via data.frame function2.3.2 via index function2.3.3 via subset function3 Change object’s charactersitics3.1 characters to factores
3.2 factores to vectores4 Create new variables4.1 Transformation of two single variables4.2 Transformation of multible variables4.3 rowSums and rowMeans function4.4 Center and standardize variables4.</description>
    </item>
    
    <item>
      <title>Data Management in R</title>
      <link>/2018/08/21/data-management-in-r/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/21/data-management-in-r/</guid>
      <description>Table of Content1 Introduction2 Combine Observations2.1 Special Case 1: Different variables within a Data Frame2.2 special case 2: Combine Observations with different colnames3 Combine Variables3.1 Special case 1: Combine variables by one variable with different spellings3.2 Special case 2: Combine variables with different number of observations4 Conclusion1 IntroductionIn dem nachfolgenden Post geht es um Data Management in R.</description>
    </item>
    
    <item>
      <title>Data Transformation in R</title>
      <link>/2018/08/18/data-transformation-in-r/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/18/data-transformation-in-r/</guid>
      <description>Table of Content1 Introduction2 Overview2.1 filter()2.2 select()2.3 mutate()2.4 arrange()2.5 summarize()3 Combinations4 Conclusion5 Bibliography1 IntroductionIn dem nachfolgenden Post geht es um Data Transformation in R. Je nach Blickwinkel fällt dieses Thema in den Bereich Data Data Wrangling oder Data Exploration (Wickham &amp;amp; Grolemund, 2016).
Quelle: Wickham, H., &amp;amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data.</description>
    </item>
    
    <item>
      <title>Easy Plotting - Data Visualization with R</title>
      <link>/2018/08/12/easy-plotting/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/12/easy-plotting/</guid>
      <description>Table of Content1 Introduction2 Overview3 Type of Graphs3.1 Bar Graph3.2 Histogram3.3 Scatter Plot3.4 Line Graph3.5 Box Plot4 Labeling and further commands5 Conclusion1 IntroductionIn dem nachfolgenden Post geht es um eine kurze Einführung zum Thema Visualisierung. Es sollen die am häufigsten verwendeten Grafiken in R vorgestellt werden und wann sie zu verwenden sind. Für diese Arbeit wurde der Datensatz insurance von der Statsistik-Plattform Kaggle https://www.</description>
    </item>
    
    <item>
      <title>Survive on the Titanic - Case Study</title>
      <link>/2018/08/05/survive-on-the-titanic-case-study/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/05/survive-on-the-titanic-case-study/</guid>
      <description>IntroductionIn der nachfolgenden Fallstudie geht es um die exemplarische Analyse nominaler Daten anhand des Untergangs der Titanic. Es soll der Hauptfrage nachgegangen werden, ob das Reisen in einer besseren Klasse die Überlebenschancen auf der Titanic erhöht hat. Für diese Untersuchung wurde der Datensatz titanic_train von der Statsistik-Plattform Kaggle https://www.kaggle.com verwendet. Eine Kopie des Datensatzes ist unter https://drive.google.com/file/d/1Q-ISaCWBl9q2egJgzgkOmWndDeBa5EXT/view?usp=drivesdk abrufbar.
library(&amp;quot;tidyverse&amp;quot;)library(&amp;quot;compute.es&amp;quot;)Titanic &amp;lt;- read_csv(&amp;quot;Titanic.csv&amp;quot;)OverviewEin erster Blick auf die Daten zeigt uns, welche Variablen mit wie vielen Observations vorliegen.</description>
    </item>
    
  </channel>
</rss>