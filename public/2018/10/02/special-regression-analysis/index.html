<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.46" />


<title>Special Regression Analysis - Michael Fuchs</title>
<meta property="og:title" content="Special Regression Analysis - Michael Fuchs">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/MFuchs.png"
         width="50"
         height="50"
         alt="MFuchs">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/MFuchs1989/Bdown">GitHub</a></li>
    
    <li><a href="https://www.linkedin.com/in/michael-fuchs-139172131/">LinkedIn</a></li>
    
    <li><a href="https://twitter.com/Stat_Michael">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">14 min read</span>
    

    <h1 class="article-title">Special Regression Analysis</h1>

    
    <span class="article-date">2018/10/02</span>
    

    <div class="article-content">
      <pre class="r"><code>library(tidyverse)
library(psych)
library(rockchalk)</code></pre>
<pre class="r"><code>affairs &lt;- read_csv(&quot;Affairs.csv&quot;)</code></pre>
<div id="table-of-content" class="section level1">
<h1>Table of Content</h1>
<ul>
<li>1 Introduction</li>
<li>2 Categorical predictors</li>
<li>3 Moderated regression</li>
<li>4 Non-linear regression</li>
<li>5 Analysis of covariance (ANCOVA)</li>
<li>6 Logistic regression</li>
<li>7 Conclusion</li>
</ul>
</div>
<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Aufbauend auf den Post <a href="https://michael-fuchs.netlify.com/2018/09/21/regression-analysis/">“Regression Analysis”</a> soll im Nachfolgenden spezielle Regressionsmodelle vorgestellt werden.</p>
<p>Für diesen Beitrag wurde der Datensatz <em>Affairs</em> von der Statistik Plattform <a href="https://www.kaggle.com">“Kaggle”</a> verwendet. Eine Kopie des Datensatzes ist unter <a href="https://drive.google.com/open?id=1N4osROEo724c7OZA2ARiwEthcZDwLxtf" class="uri">https://drive.google.com/open?id=1N4osROEo724c7OZA2ARiwEthcZDwLxtf</a> abrufbar.</p>
</div>
<div id="categorical-predictors" class="section level1">
<h1>2 Categorical predictors</h1>
<p>Mit dem allgemeinen linearen Modell lassen sich sowohl kontinuierliche Prädiktoren (wie bei der einfachen Regressionsanalyse) als auch kategoriale Prädiktoren (wie bei der Varianzanalyse) analysieren. Der <em>lm</em> Befehl ändert sich dadurch nicht. R erkennt automatisch, dass es sich im nachfolgenden Fall bei der Prädiktorvariable um einen Faktor handelt. Für dieses Beispiel wird die Variable <code>religiousness</code> entsprechend umkodiert.</p>
<pre class="r"><code>affairs$religiousness.r &lt;- recode(affairs$religiousness, `1`=&quot;Gruppe 1&quot;, `2`=&quot;Gruppe 2&quot;, `3`=&quot;Gruppe 3&quot;, `4`=&quot;Gruppe 4&quot;, `5`=&quot;Gruppe 5&quot;)</code></pre>
<p>Nun erfolgt die <em>lm</em> Syntax wie gewohnt. Es soll untersucht werden, ob es Altersunterschiede zwischen den verschiedenen Gruppen gibt.</p>
<pre class="r"><code>lm.kat &lt;- lm(affairs$age ~ affairs$religiousness.r)
summary(lm.kat)</code></pre>
<pre><code>## 
## Call:
## lm(formula = affairs$age ~ affairs$religiousness.r)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -19.221  -6.687  -1.687   5.926  26.562 
## 
## Coefficients:
##                                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                      30.4375     1.3143  23.158  &lt; 2e-16 ***
## affairs$religiousness.rGruppe 2   0.5655     1.4943   0.378 0.705225    
## affairs$religiousness.rGruppe 3   0.6361     1.5396   0.413 0.679611    
## affairs$religiousness.rGruppe 4   3.2493     1.4710   2.209 0.027561 *  
## affairs$religiousness.rGruppe 5   6.2839     1.7065   3.682 0.000252 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.106 on 596 degrees of freedom
## Multiple R-squared:  0.04538,    Adjusted R-squared:  0.03897 
## F-statistic: 7.083 on 4 and 596 DF,  p-value: 1.419e-05</code></pre>
<p>Das durchschnittliche Alter in der Referenzgruppe “Gruppe1” beträgt 30,44 Jahre. Dieser Wert zeigt mit p &lt; .001, dass dieser Koeffizient signifikant von Null verschieden ist. Die weiteren Koeffizienten drücken die Unterschiede zwischen den jeweiligen Gruppen und der Referenzgruppe aus. Gruppe 2 und 3 sind nicht signifikant, d.h. es gibt keine Gruppenunterschiede in den Mittelwerten. Dahingegen ist Gruppe 4 leicht und Gruppe 5 stark signifikant.</p>
</div>
<div id="moderated-regression" class="section level1">
<h1>3 Moderated regression</h1>
<p>Bei der moderierten Regression wird überprüft, ob der Einfluss eines Prädiktors auf das Kriterium von der Ausprägung einer dritten Moderatorvariable abhängt. Für die nachfolgende Untersuchung ist es ratsam, die verwendeten Prädiktoren zu zentrieren (siehe hierzu auch Post <a href="https://michael-fuchs.netlify.com/2018/08/24/edit-variables-in-r/">“Change Variables in R”</a> Punkt 4.4). Es soll untersucht werden, ob die Anzahl der Affären (<code>affairs</code>) vom Alter (<code>age</code>) und vom Bildungsstand (<code>education</code>) abhängig sind. Das Alter soll hierbei der Prädiktor (X) sein, die Anzahl der Affären das Kriterium (Y) und der Bildungsstand (Z) soll als Moderatorvariable dienen.</p>
<pre class="r"><code>age.cen &lt;- as.numeric(scale(affairs$age, scale = FALSE))
education.cen &lt;- as.numeric(scale(affairs$education, scale = FALSE))
affairs.normal &lt;- as.numeric(affairs$affairs)

lm.mod &lt;- lm(affairs.normal ~ age.cen * education.cen)

summary(lm.mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = affairs.normal ~ age.cen * education.cen)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.789 -1.564 -1.258 -0.860 10.899 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            1.436301   0.135077  10.633   &lt;2e-16 ***
## age.cen                0.036177   0.014643   2.471   0.0138 *  
## education.cen         -0.038808   0.058195  -0.667   0.5051    
## age.cen:education.cen  0.006538   0.005400   1.211   0.2265    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.288 on 597 degrees of freedom
## Multiple R-squared:  0.01173,    Adjusted R-squared:  0.006768 
## F-statistic: 2.363 on 3 and 597 DF,  p-value: 0.07025</code></pre>
<p>Der Haupteffekt Alter ist signifikant, d.h. die Anzahl an Affären steigt mit dem Alter, bei einem durchschnittlichen Bildungsgrad, an. Der Haupteffekt Bildungsgrad ist mit p = .505 nicht signifikant, d.h. es gibt keinen Zusammenhang zwischen Bildungsgrad und der Anzahl an Affären, wenn das Alter einen durchschnittlichen Wert aufweist. Der Interaktionseffekt ist zwar ebenfalls nicht signifikant, er wird aber für dieses Beispiel dennoch weiter untersucht. Für die Interpretation des Interaktionseffektes bieten sich bedingte Regressionsgleichungen zur Veranschaulichung an. Dabei wird die Auswirkung des Prädiktors (x) auf das Kriterium (Y) für verschiedene Ausprägungen der Moderatorvariable (Z) berechnet.</p>
<pre class="r"><code>Steigung &lt;- plotSlopes(lm.mod, plotx = &quot;age.cen&quot;, modx = &quot;education.cen&quot;)</code></pre>
<p><img src="/post/2018-10-02-special-regression-analysis_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Zu Beginn der <em>plotSlopes</em> Funktion wird der Name des Regressionsmodells genannt. <em>plotx = “”</em> beinhaltet den Namen der Variable X und <em>modx =“”</em> den Namen der Variablen Z (für die die bedingte Regressionsgleichung erstellt werden sollen).</p>
<p>Es werden drei bedingte Regressionsgleichung, für die Quartile der Moderatorvariablen, in der Abbildung dargestellt.</p>
<p>Das Objekt “Steigung” enthält folgende Werte.</p>
<pre class="r"><code>Steigung</code></pre>
<pre><code>## $call
## plotSlopes.lm(model = lm.mod, plotx = &quot;age.cen&quot;, modx = &quot;education.cen&quot;)
## 
## $newdata
##     age.cen education.cen       fit
## 1 -14.98752    -2.1663894 1.1904443
## 2 -14.98752    -0.1663894 0.9168548
## 3 -14.98752     1.8336106 0.6432654
## 4  24.51248    -2.1663894 2.0599861
## 5  24.51248    -0.1663894 2.3028881
## 6  24.51248     1.8336106 2.5457901
## 
## $modxVals
##        25%        50%        75% 
## -2.1663894 -0.1663894  1.8336106 
## 
## $col
## 25% 50% 75% 
##   1   2   3 
## 
## $lty
## 25% 50% 75% 
##   1   2   3 
## 
## attr(,&quot;class&quot;)
## [1] &quot;plotSlopes&quot; &quot;rockchalk&quot;</code></pre>
<p>Die <em>$modxVals</em> Angabe enthält die Werte der Moderatorvariablen, die für die Berechnung der bedingten Regressionsgleichungen eingesetzt wurden.</p>
<p>Nun soll untersucht werden, unter welchen Umständen sich die bedingten Regressionsgewichte signifikant von Null unterscheiden. Dies kann mittels der <em>testSlopes</em> Funktion berechnet werden.</p>
<pre class="r"><code>testSlopes(Steigung)</code></pre>
<pre><code>## Values of education.cen INSIDE this interval:
##         lo         hi 
## -0.9901723  6.9786332 
## cause the slope of (b1 + b2*education.cen)age.cen to be statistically significant</code></pre>
<p>Das Regressionsgewicht ist signifikant von Null verschieden, wenn der Wert der Moderatorvariablen kleiner als -0,99 oder größer als 6,98 ist.</p>
<pre class="r"><code>affairs$age.cen &lt;- as.numeric(scale(affairs$age, scale = FALSE))
affairs$education.cen &lt;- as.numeric(scale(affairs$education, scale = FALSE))
affairs$affairs.normal &lt;- as.numeric(affairs$affairs)


m.mod &lt;- mediate(affairs.normal ~ age.cen + (education.cen), data = affairs)
mediate(y = affairs.normal ~ age.cen + (education.cen), data = affairs)</code></pre>
<p><img src="/post/2018-10-02-special-regression-analysis_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre><code>## 
## Mediation/Moderation Analysis 
## Call: mediate(y = affairs.normal ~ age.cen + (education.cen), data = affairs)
## 
## The DV (Y) was  affairs.normal . The IV (X) was  age.cen . The mediating variable(s) =  education.cen .
## 
## Total effect(c) of  age.cen  on  affairs.normal  =  0.03   S.E. =  0.01  t  =  2.34  df=  598   with p =  0.02
## Direct effect (c&#39;) of  age.cen  on  affairs.normal  removing  education.cen  =  0.03   S.E. =  0.01  t  =  2.37  df=  598   with p =  0.018
## Indirect effect (ab) of  age.cen  on  affairs.normal  through  education.cen   =  0 
## Mean bootstrapped indirect effect =  0  with standard error =  0  Lower CI =  -0.01    Upper CI =  0
## R = 0.1 R2 = 0.01   F = 2.81 on 2 and 598 DF   p-value:  0.0611 
## 
##  To see the longer output, specify short = FALSE in the print statement or ask for the summary</code></pre>
<pre class="r"><code>summary(mediate(y = affairs.normal ~ age.cen + (education.cen), data = affairs))</code></pre>
<pre><code>## Call: mediate(y = affairs.normal ~ age.cen + (education.cen), data = affairs)
## 
##  Total effect estimates (c) 
##         affairs.normal   se    t  df   Prob
## age.cen           0.03 0.01 2.34 598 0.0195
## 
## Direct effect estimates     (c&#39;) 
##               affairs.normal   se     t  df   Prob
## age.cen                 0.03 0.01  2.37 598 0.0181
## education.cen          -0.02 0.06 -0.38 598 0.7050
## 
## R = 0.1 R2 = 0.01   F = 2.81 on 2 and 598 DF   p-value:  0.0611 
## 
##  &#39;a&#39;  effect estimates 
##         education.cen   se    t  df    Prob
## age.cen          0.03 0.01 3.32 599 0.00094
## 
##  &#39;b&#39;  effect estimates 
##               affairs.normal   se     t  df  Prob
## education.cen          -0.02 0.06 -0.38 598 0.705
## 
##  &#39;ab&#39;  effect estimates 
##         affairs.normal boot sd lower upper
## age.cen              0    0  0 -0.01     0</code></pre>
</div>
<div id="non-linear-regression" class="section level1">
<h1>4 Non-linear regression</h1>
<p>Bei nicht linearen Regressionen soll untersucht werden, ob die Auswirkung einer Variablen X auf das Kriterium Y ab einen gewissen Grad stärker zunimmt, abnimmt oder sich sogar in die entgegengesetzte Richtung umschwenkt. Beispielhaft kann man hier Untersuchungen zum Kaffeekonsum erwähnen. Kaffee (beziehungsweise das Koffein) bewirkt zum Anfang eine positive Auswirkung auf die Konzentration. Ab einer bestimmten Menge an Kaffee flacht die Auswirkungen auf die Konzentrationsfähigkeit ab und bewirkt bei weiterer Zuführung von Koffein sogar eine Beeinträchtigung der Konzentration.</p>
<p>Nicht lineare Zusammenhänge können in der Regressionsanalyse modelliert werden, wenn Polynome höherer Ordnung in die Gleichung aufgenommen werden.</p>
<p>Es soll untersucht werden, ob die Anzahl an verheirateten Jahren, einen nicht linearen Zusammenhang zu der Anzahl an Affären aufweisen. Dafür ist es wieder notwendig, die zu untersuchenden Variablen zu zentrieren (die Variable <code>affairs</code> wurde bereits zentriert und unter dem Objekt “affairs.normal” abgespeichert).</p>
<pre class="r"><code>years.married.cen &lt;- as.numeric(scale(affairs$yearsmarried, scale = FALSE))</code></pre>
<p>Anschließend wird das nicht lineare Modell spezifiziert, indem die <code>years.married</code> Variable zweimal aufgnommen wird.</p>
<pre class="r"><code>lm.nlm &lt;- lm(affairs.normal ~ years.married.cen + I(years.married.cen^2))
summary(lm.nlm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = affairs.normal ~ years.married.cen + I(years.married.cen^2))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.1033 -1.9001 -1.0936 -0.3194 11.5994 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             1.720059   0.241827   7.113 3.26e-12 ***
## years.married.cen       0.114330   0.023921   4.779 2.22e-06 ***
## I(years.married.cen^2) -0.008524   0.006534  -1.305    0.193    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.241 on 598 degrees of freedom
## Multiple R-squared:  0.03765,    Adjusted R-squared:  0.03443 
## F-statistic:  11.7 on 2 and 598 DF,  p-value: 1.039e-05</code></pre>
<p>Nur ein Regressionsgewicht der Prädiktoren ist signifikant von Null verschieden, d.h. es liegt <strong>kein kurvilinearer Zusammenhang</strong> vor. Dafür müssten beide Regressionsgewichtet sich signifikant von Null unterscheiden. Wäre dies der Fall, so könnte man für eine vereinfachte Interpretation folgende Grafik (Streudiagramm) erstellen.</p>
<pre class="r"><code>plot(years.married.cen, affairs.normal, xlab = &quot;Anzahl verheirateter Jahre zentriert&quot;, ylab = &quot;Affären vs. Treue&quot;)
curve(1.720059 + 0.114330*x - 0.008524*(x^2), add=TRUE)
abline(lm(affairs.normal ~ years.married.cen))</code></pre>
<p><img src="/post/2018-10-02-special-regression-analysis_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="analysis-of-covariance-ancova" class="section level1">
<h1>5 Analysis of covariance (ANCOVA)</h1>
<p>Die Kovarianzanalyse erlaubt die Kombination von kategorialen und metrischen Prädiktoren in einem einzigen linearen Modell. Im Nachfolgenden soll der Einfluss des Alters (zentriert) und des Geschlechts auf die Anzahl an Affären untersucht werden.</p>
<pre class="r"><code>sex &lt;- affairs$gender
table(sex)</code></pre>
<pre><code>## sex
## female   male 
##    315    286</code></pre>
<p>Merke: “female” wird an erster Stelle genannt.</p>
<pre class="r"><code>cov &lt;- lm(affairs.normal ~ age.cen * sex)
summary(cov)</code></pre>
<pre><code>## 
## Call:
## lm(formula = affairs.normal ~ age.cen * sex)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.511 -1.570 -1.261 -1.030 11.135 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      1.48930    0.18895   7.882 1.53e-14 ***
## age.cen          0.04167    0.02148   1.940   0.0529 .  
## sexmale         -0.04423    0.27385  -0.162   0.8717    
## age.cen:sexmale -0.01397    0.02952  -0.473   0.6362    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.291 on 597 degrees of freedom
## Multiple R-squared:  0.009485,   Adjusted R-squared:  0.004507 
## F-statistic: 1.906 on 3 and 597 DF,  p-value: 0.1275</code></pre>
<p>Der vorhergesagt Wert (Intercept) für Frauen (wg erster Stelle der <em>table(sex)</em> Funktion) beträgt 1,49 bei durchschnittlichem Alter. Der Koeffizient <em>age.cen</em> beschreibt den Zusammenhang zwischen Alter und der Anzahl an Affären für Frauen. Der Koeffizient <em>sexmale</em> drückt hier den Unterschied zwischen Männer und Frauen hinsichtlich der Anzahl an Affären bei durchschnittlichem Lebensalter aus. Der Interaktionseffekt (<em>age.cen:sexmale</em>) beschreibt das Ausmaß, in dem sich die Stärke des Zusammenhangs zwischen Alter und Anzahl an Affären für Männer von den Frauen unterscheidet. In dem vorangegangenen Beispiel sind weder die Haupteffekte noch der Interaktionseffekt statistisch signifikant. Wäre der Interaktionseffekt signifikant gewesen, so würde sich zur besseren Interpretation (wie bei der moderierten Regression) die Berechnung und die graphische Darstellung der bedingten Regressionsgleichungen anbieten.</p>
<pre class="r"><code>Steigung2 &lt;- plotSlopes(cov, plotx = &quot;age.cen&quot;, modx = &quot;sex&quot;)</code></pre>
<p><img src="/post/2018-10-02-special-regression-analysis_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Anschließend wird noch ein Signifikanztest für die beiden Regressionsgewichte durchgeführt.</p>
<pre class="r"><code>testSlopes(Steigung2)</code></pre>
<pre><code>## These are the straight-line &quot;simple slopes&quot; of the variable age.cen  
##  for the selected moderator values. 
##             &quot;sex&quot;      slope Std. Error  t value   Pr(&gt;|t|)
## 1         age.cen 0.04167150 0.02148213 1.939822 0.05287201
## 2 age.cen:sexmale 0.02769793 0.02025154 1.367695 0.17192212</code></pre>
<p>Dieser Ausgabe kann entnommen werden, dass weder das Lebensalter bei Frauen (p = .053) noch das bei Männern (p= .172) signifikant mit der Anzahl an Affären zusammenhängt.</p>
</div>
<div id="logistic-regression" class="section level1">
<h1>6 Logistic regression</h1>
<p>Die bisherig vorgestellten speziellen Regressionsmodelle hatten die Gemeinsamkeit, dass das untersuchte Kriterium metrisch war. Mit der logistischen Regression ist es möglich, eine kategoriale abhängige Variable zu analysieren. Diese muss auch nicht zwingend dichotom sein, sondern kann auch mehr als zwei Ausprägungen besitzen.</p>
<p>Im folgenden Beispiel soll der Unterschied zwischen Männer und Frauen Frauen hinsichtlich des Bildungsgrades untersucht werden. Das Geschlecht ist hierbei das Kriterium. Für die logistische Regression ist es wichtig, dass die erste Kategorie mit 0 und die zweite Kategorie mit 1 kodiert ist.</p>
<pre class="r"><code>affairs$gender.r &lt;- recode(affairs$gender, `male`=&quot;0&quot;, `female`=&quot;1&quot;)
sex.r &lt;- as.numeric(affairs$gender.r)</code></pre>
<p>Im zweiten Schritt wird die unabhängige Variable einem Objekt zugeordnet.</p>
<pre class="r"><code>education.normal &lt;- as.numeric(affairs$education)</code></pre>
<p>Modelle mit nicht-metrischen abhängigen Variablen werden als Generalized Linear Models (Generalisierte Lineare Modelle) bezeichnet und können in R mit der <em>glm</em> Funktion berechnet werden. Im nachfolgenden Beispiel wird eine lineare Regression mit der abhängigen Variable <code>sex.r</code> und der unabhängigen Variable <code>education.normal</code> angefordert.</p>
<pre class="r"><code>log.lm &lt;- glm(sex.r ~ education.normal, family = binomial)</code></pre>
<p>Auch bei dem <em>glm</em> Befehl funktioniert die <em>summary</em> Funktion.</p>
<pre class="r"><code>summary(log.lm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = sex.r ~ education.normal, family = binomial)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4333  -0.9405   0.5680   1.0980   1.7838  
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)       6.40144    0.70153   9.125   &lt;2e-16 ***
## education.normal -0.38823    0.04266  -9.100   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 831.76  on 600  degrees of freedom
## Residual deviance: 729.05  on 599  degrees of freedom
## AIC: 733.05
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Für den Prädiktor <code>education.normal</code> erhalten wir den Regressionskoeffizienten b<sub>1</sub>=-0,39, z=-9,1, p&lt;.001. Der Bildungsgrad ist also ein signifikanter Prädiktor für die Variable <code>sex.r</code>. Zur genaueren Interpretation dieses Koeffizienten wird daran erinnert, dass die zweite Kategorie (female) mit 1 kodiert worden ist. Der Regressionskoeffizient wird daher wie folgt interpretiert: Wenn man den Bildungsgrad um eine Einheit erhöht, reduziert sich der Logit um -0,39. Der Logit ist der natürliche Logarithmus des Wettquotienten. Der Achsenabschnitt (Intercept, hier 6,40) drückt die Höhe des Logits für einen Bildungsgrad von Null aus. Des Weiteren erhalten wir mit der <em>summary</em> Funktion bei <em>glm</em> Modellen Angaben zu den Devianzen. Diese sind ein Maß für die Modellgüte. Je kleiner die Devianz ist, desto besser passt das Modell auf die Daten. Die Zeile <em>Null deviance</em> enthält die Devianz des Nullmodells (ein Modell, das keien Prädiktoren enthält). Die Zeile <em>Residual deviance</em> ist die Devianz für das von uns durchgeführte Modell. Diese Devianz sollte deutlich kleiner sein als die von dem Nullmodell. Die Angabe <em>AIC</em> steht für Akaikes Information Criterion und ist ebenfalls ein Indikator für die Modellgüte. Je kleiner der AIC ausfällt, desto besser ist das Modell. Die Ausgabe <em>Number of Fisher Scoring iterations: 4</em> zeigt an, wie viele Iterationen benötigt wurden, um die Modellparameter zu schätzen. Eine hohe Anzahl (&gt; 25) würde darauf hindeute, dass das Modell nicht gut auf die Daten passt.</p>
<p>Zusätzlich zu den Regressionskoeffizienten wird das Odds Ratio berechnet. Dies dient auch als Effektgröße für die einzelnen Koeffizienten. Als erstes werden nochmals die Regressionskoeffizienten des “log.lm” Objektes angefordert.</p>
<pre class="r"><code>coef(log.lm)</code></pre>
<pre><code>##      (Intercept) education.normal 
##        6.4014447       -0.3882297</code></pre>
<p>Das Odds Ratio lässt sich aus den Koeffizienten berechnen, indem man diese exponiert.</p>
<pre class="r"><code>exp(coef(log.lm))</code></pre>
<pre><code>##      (Intercept) education.normal 
##      602.7151603        0.6782565</code></pre>
<p>Zusätzlich können Konfidenzintervalle für das Odds Ratio angefordert werden.</p>
<pre class="r"><code>exp(confint(log.lm))</code></pre>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                      2.5 %       97.5 %
## (Intercept)      157.82480 2476.8976498
## education.normal   0.62243    0.7358748</code></pre>
<p>Ähnlich wie bei der multiplen linearen Regression kann auch bei der logistischen Regression verschiedene Modelle miteinander verglichen werden (hierarchisches Vorgehen). Im ersten Modell wurde der Unterschied zwischen Männer und Frauen hinsichtlich des Bildungsgrades untersucht (hier nochmal neu abgespeichert unter dem Objekt “log.lm1”).</p>
<pre class="r"><code>log.lm1 &lt;- glm(sex.r ~ education.normal, family = binomial)</code></pre>
<p>In einem weiteren Modell soll der Unterschied zwischen Männer und Frauen hinsichtlich des Bildungsgrades <strong>und</strong> der Religiosität untersucht werden.</p>
<pre class="r"><code>reli &lt;- as.numeric(affairs$religiousness)
log.lm2 &lt;- glm(sex.r ~ education.normal + reli, family = binomial)
summary(log.lm2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = sex.r ~ education.normal + reli, family = binomial)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4196  -0.9781   0.5532   1.0765   1.8053  
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)       6.56873    0.75431   8.708   &lt;2e-16 ***
## education.normal -0.38943    0.04276  -9.107   &lt;2e-16 ***
## reli             -0.04789    0.07698  -0.622    0.534    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 831.76  on 600  degrees of freedom
## Residual deviance: 728.66  on 598  degrees of freedom
## AIC: 734.66
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Der zusätzliche Prädiktor <code>reli</code> ist nicht signifikant (b<sub>2</sub>=-0,05, z=-,62, p=.534).</p>
<p>Nun werden die beiden Modelle auf Signifikanz getestet.</p>
<pre class="r"><code>anova(log.lm1, log.lm2, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: sex.r ~ education.normal
## Model 2: sex.r ~ education.normal + reli
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1       599     729.05                     
## 2       598     728.66  1  0.38756   0.5336</code></pre>
<p>Die <em>Resid. Df</em> Spalte enthält die Freiheitsgrade und die <em>Resid. Dev</em> Spalte die Residualdevianzen der beiden Modellgleichungen. Die Residualdevianz des zweiten Modells (D<sub>2</sub> = 728,66) fällt etwas kleiner aus als die Residualdevianz des ersten Modells (D<sub>1</sub> = 729,05). Das zweite Modell passt demnach etwas besser auf die Daten. Diese Verbesserung muss aber noch auf Signifikanz überprüft werden. Die Spalte <em>Deviance</em> enthält den Chi^2-Wert (die Differenz der beiden Devianzen) und die dazugehörigen Freiheitsgrade für den Test sind unter der Spalte <em>Df</em> aufgeführt. Diese entsprechen der Differenz der Freiheitsgrade der beiden Modelle, hier also 599-598 = 1 Freiheitsgrad. Der durchgeführte Chi^2-Test ist mit chi^2=0,39, df=1, p=.534 nicht signifikant. Dies bedeutet, dass das zweite Modell nicht signifikant besser auf die Daten passt als das sparsamere Modell. Es wird daher das Modell 1 (log.lm1) bevorzugt.</p>
</div>
<div id="conclusion" class="section level1">
<h1>7 Conclusion</h1>
<p>Ergänzend zu dem Post <a href="https://michael-fuchs.netlify.com/2018/09/21/regression-analysis/">“Regression Analysis”</a> wurde in diesem Beitrag die Aufnahme von kategorialen Prädiktoren (Punkt 2) in lineare Regressionsmodelle behandelt. Des Weiteren wurde gezeigt, wie eine moderierte Regression (Punkt 3) durchgeführt und interpretiert werden kann. Die Modellierung nicht-linearer Zusammenhänge wurde unter Punkt 4 thematisiert. Zum Schluss war die logistische Regression (Punkt 5), bei der eine dichotome abhängige Variable vorlag, zentral.</p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

